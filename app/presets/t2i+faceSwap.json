{
  "6": {
    "inputs": {
      "text": "A scene of a young man struggling to carry a large, heavy bundle of wooden logs strapped to his back with thick ropes. He is wearing traditional, rough-hewn clothing, suitable for a historical or feudal era setting. His expression shows visible strain and determination as he braces himself under the massive weight. The scene is set on a dirt road lined with rough wooden fences, with greenery and bushes on either side. The sky is overcast, casting soft, diffused lighting over the entire scene, giving it a dramatic, almost cinematic look. The atmosphere feels gritty and intense, with earthy tones dominating the palette. The details of the logs, ropes, and surrounding vegetation are hyper-realistic, emphasizing the weight and labor in the scene.",
      "clip": [
        "43",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Positive Prompt)"
    }
  },
  "8": {
    "inputs": {
      "samples": [
        "31",
        0
      ],
      "vae": [
        "30",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "9": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "44",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "27": {
    "inputs": {
      "width": [
        "38",
        0
      ],
      "height": [
        "38",
        1
      ],
      "batch_size": 1
    },
    "class_type": "EmptySD3LatentImage",
    "_meta": {
      "title": "EmptySD3LatentImage"
    }
  },
  "30": {
    "inputs": {
      "ckpt_name": "flux1-schnell-fp8.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "31": {
    "inputs": {
      "seed": 173805153958732,
      "steps": 4,
      "cfg": 1,
      "sampler_name": "euler",
      "scheduler": "simple",
      "denoise": 1,
      "model": [
        "43",
        0
      ],
      "positive": [
        "6",
        0
      ],
      "negative": [
        "33",
        0
      ],
      "latent_image": [
        "27",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "33": {
    "inputs": {
      "text": "",
      "clip": [
        "43",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Negative Prompt)"
    }
  },
  "38": {
    "inputs": {
      "megapixel": "1.0",
      "aspect_ratio": "1:1 (Perfect Square)",
      "divisible_by": "64",
      "custom_ratio": false,
      "custom_aspect_ratio": "1:1"
    },
    "class_type": "FluxResolutionNode",
    "_meta": {
      "title": "Flux Resolution Calc"
    }
  },
  "42": {
    "inputs": {
      "format": "PNG",
      "images": [
        "44",
        0
      ]
    },
    "class_type": "ETN_SendImageWebSocket",
    "_meta": {
      "title": "Send Image (WebSocket)"
    }
  },
  "43": {
    "inputs": {
      "lora_name": "aidmaFLUXPro1.1-FLUX-v0.3.safetensors",
      "strength_model": 0.5000000000000001,
      "strength_clip": 0.5000000000000001,
      "model": [
        "30",
        0
      ],
      "clip": [
        "30",
        1
      ]
    },
    "class_type": "LoraLoader",
    "_meta": {
      "title": "Load LoRA"
    }
  },
  "44": {
    "inputs": {
      "enabled": true,
      "swap_model": "inswapper_128.onnx",
      "facedetection": "retinaface_resnet50",
      "face_restore_model": "none",
      "face_restore_visibility": 1,
      "codeformer_weight": 0.5,
      "detect_gender_input": "male",
      "detect_gender_source": "male",
      "input_faces_index": "0",
      "source_faces_index": "0",
      "console_log_level": 1,
      "input_image": [
        "8",
        0
      ],
      "source_image": [
        "50",
        0
      ],
      "face_boost": [
        "46",
        0
      ]
    },
    "class_type": "ReActorFaceSwap",
    "_meta": {
      "title": "ReActor ðŸŒŒ Fast Face Swap"
    }
  },
  "46": {
    "inputs": {
      "enabled": true,
      "boost_model": "GFPGANv1.4.pth",
      "interpolation": "Bilinear",
      "visibility": 1,
      "codeformer_weight": 0.5,
      "restore_with_main_after": false
    },
    "class_type": "ReActorFaceBoost",
    "_meta": {
      "title": "ReActor ðŸŒŒ Face Booster"
    }
  },
  "50": {
    "inputs": {
      "image": ""
    },
    "class_type": "ETN_LoadImageBase64",
    "_meta": {
      "title": "Load Image (Base64)"
    }
  }
}